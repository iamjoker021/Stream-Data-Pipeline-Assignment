# Stream-Data-Pipeline-Assignment
This Project is used to learn Kafka to create Assignment Project

## Goal:
Create a Streaming Data Pipeline using Kafka

## Step 1:
Create a Kafka Producer and Consumer to send and consume any sample data. I did thi as first steps so that I can extablish the pipeline.
GitHub Reference: https://github.com/dstaka/kafka-spark-demo-pyconsg19
Learning Reference: https://www.youtube.com/watch?v=w6A-uDEb7JY&list=PLjfRmoYoxpNrs0VmIq6mOTqXP52RfZdRf

## Step 2:
Fetch data from yfinance for one day and send the data from Producer and conume via Consumer.

## Step 3:
After consuming the data in Kafka Consumer. Find the rolling average for analysis.

## Step 4:
After finding the rolling average plot the data in Dashboard. I used the code from below GitHib url for straming data in Streamlit Dashboard
GitHub Reference: https://github.com/amrrs/real-time-live-streamlit-dashboard-python?ref=blog.streamlit.io

---
The Sample Video:
[streamlit-Kafka_Consumer-2023-04-02-18-04-79.webm](https://user-images.githubusercontent.com/84496123/231730367-503295af-90c0-408f-97f3-d3c4a294756b.webm)


Please feel free to suggest any improvements.

Thanks